from flask import Flask, request, jsonify
import os
import json
import subprocess
import threading
import shutil
import io
import base64
import requests
import random
import numpy as np
import cv2
import torch
import boto3
import matplotlib.pyplot as plt
import svgwrite
import cairosvg
from PIL import Image
from dotenv import load_dotenv
from sklearn.cluster import KMeans
from sklearn.neighbors import kneighbors_graph
from scipy.sparse.csgraph import minimum_spanning_tree, connected_components
from sklearn.metrics import pairwise_distances
from peft import PeftModel
from diffusers import StableDiffusionPipeline
import gc

# Pinecone & OpenAI
import pinecone
from pinecone import Pinecone
import openai
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI

# Diffusers & Segmentation Models
from diffusers import DiffusionPipeline, UNet2DConditionModel
from segment_anything import sam_model_registry, SamPredictor
from ultralytics import YOLO, SAM

# AWS
from botocore.client import Config

import datetime
from PIL import ImageStat

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# AWS í™˜ê²½ë³€ìˆ˜
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
BUCKET_NAME = os.getenv("BUCKET_NAME")

# dreambooth
MODEL_NAME = "runwayml/stable-diffusion-v1-5" 
TRAIN_SCRIPT = "./train_dreambooth.py"

# open_ai & Pinecone
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")

# ì¥ë¡€ì‹ì¥ ì •ë³´ JSON ë¡œë“œ
FUNERAL_JSON_PATH = "./funeral_service.json"
def load_json_data(file_path):
    """JSON íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            return json.load(file)
    except Exception as e:
        print(f"JSON ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []
funeral_data = load_json_data(FUNERAL_JSON_PATH)

training_status = {"status": "idle"}
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# SAM

# sam_checkpoint = "./sam_vit_b_01ec64.pth"  # SAM checkpoint íŒŒì¼ ê²½ë¡œ
# # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ê²€ì¦ (íŒŒì¼ì´ ì‹¤ì œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸)
# if not os.path.isfile(sam_checkpoint):
#     raise FileNotFoundError(f"Model checkpoint file '{sam_checkpoint}' not found.")
# model_type = "vit_b"
# state_dict = torch.load(sam_checkpoint, weights_only=True)
# sam = sam_model_registry[model_type](checkpoint=None)  # Load without unsafe data
# sam.load_state_dict(state_dict)
# predictor = SamPredictor(sam)

yolo_model = YOLO("yolov8x.pt")
sam_model = SAM("sam_b.pt")

# Pinecone ì´ˆê¸°í™”
pc = Pinecone(api_key=PINECONE_API_KEY)
# Pinecone ì¸ë±ìŠ¤ ì—°ê²°
index_meritz = pc.Index("meritz")
index_samsung = pc.Index("samsung")
index_hanhwa = pc.Index("hanwha")
index_diagnostic = pc.Index("diagnostic")

app = Flask(__name__)

# S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
s3_client = boto3.client(
    "s3",
    aws_access_key_id=AWS_ACCESS_KEY_ID,
    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
    config=Config(signature_version='s3v4')
)

def download_s3_images(image_urls, save_dir):
    os.makedirs(save_dir, exist_ok=True)
    
    for i, url in enumerate(image_urls):
        https_url = url  # S3 URLì„ HTTPSë¡œ ë³€í™˜
        try:
            response = requests.get(https_url, stream=True)
            if response.status_code == 200:
                save_path = os.path.join(save_dir, f"image_{i}.jpg")
                with open(save_path, "wb") as f:
                    for chunk in response.iter_content(1024):
                        f.write(chunk)
                print(f"âœ… Downloaded: {https_url} -> {save_path}")
            else:
                print(f"âŒ Failed to download {https_url} (Status Code: {response.status_code})")
        except Exception as e:
            print(f"âŒ Error downloading {https_url}: {e}")

def stars_download_s3_images(image_urls, save_folder="./img"):
    """
    HTTP(S) í˜•ì‹ì˜ S3 ì´ë¯¸ì§€ URL ëª©ë¡ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œì»¬ í´ë”ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜.

    :param image_urls: S3ì—ì„œ ì œê³µí•˜ëŠ” ì´ë¯¸ì§€ì˜ HTTP URL ë¦¬ìŠ¤íŠ¸
    :param save_folder: ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë¡œì»¬ í´ë” (ê¸°ë³¸ê°’: ./img)
    :return: ì €ì¥ëœ ë¡œì»¬ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    if not os.path.exists(save_folder):
        os.makedirs(save_folder)

    # ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(image_urls, str):
        image_urls = [image_urls]

    if not os.path.exists(save_folder):
        os.makedirs(save_folder)

    saved_paths = []
    for image_url in image_urls:
        filename = os.path.basename(image_url)
        save_path = os.path.join(save_folder, filename)

        try:
            response = requests.get(image_url, stream=True)
            response.raise_for_status()  # HTTP ì—ëŸ¬ ì²˜ë¦¬

            with open(save_path, "wb") as file:
                for chunk in response.iter_content(1024):
                    file.write(chunk)

            print(f"âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {save_path}")
            saved_paths.append(save_path)

        except requests.exceptions.RequestException as e:
            print(f"âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {image_url}, ì˜¤ë¥˜: {e}")
    
    return saved_paths

def upload_svg_to_s3(bucket_name, object_name=None):
    """
    .svg íŒŒì¼ì„ S3ì— ì—…ë¡œë“œí•˜ê³  URLì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    :param file_path: ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
    :param bucket_name: S3 ë²„í‚· ì´ë¦„
    :param object_name: S3ì— ì €ì¥í•  íŒŒì¼ ì´ë¦„ (ê¸°ë³¸ì ìœ¼ë¡œ ë¡œì»¬ íŒŒì¼ ì´ë¦„ê³¼ ë™ì¼)
    :return: ì—…ë¡œë“œëœ íŒŒì¼ì˜ S3 URL
    """

    try:
        s3_client.upload_file(
            Filename=object_name,
            Bucket=bucket_name, 
            Key=f"test_user/{object_name}",
            ExtraArgs={'ContentType': 'image/svg+xml'}  # ì˜¬ë°”ë¥¸ SVG MIME íƒ€ì…
        )
        
        # ì—…ë¡œë“œëœ íŒŒì¼ì˜ URL ìƒì„±
        file_url = f"https://{bucket_name}.s3.amazonaws.com/test_user/{object_name}"
        return file_url

    except Exception as e:
        print(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def upload_png_to_s3(bucket_name, object_name, pet_id):
    """
    .png íŒŒì¼ì„ S3ì— ì—…ë¡œë“œí•˜ê³  URLì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    :param bucket_name: S3 ë²„í‚· ì´ë¦„
    :param object_name: S3ì— ì €ì¥í•  íŒŒì¼ ì´ë¦„
    :param pet_id: ë°˜ë ¤ë™ë¬¼ ID
    :return: ì—…ë¡œë“œëœ íŒŒì¼ì˜ S3 URL
    """
    try:
        # í˜„ì¬ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸° (YYYYMMDD í˜•ì‹)
        current_date = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
        
        # S3ì— ì—…ë¡œë“œí•  í‚¤ ê²½ë¡œ ì„¤ì • (íŒŒì¼ëª… ë’¤ì— ë‚ ì§œ ì¶”ê°€)
        object_name_with_date = f"{object_name}_{current_date}.png"
        s3_key = f"letters/{pet_id}/{object_name_with_date}"

        # íŒŒì¼ ì—…ë¡œë“œ
        s3_client.upload_file(
            Filename=object_name,
            Bucket=bucket_name, 
            Key=s3_key,
            ExtraArgs={'ContentType': 'image/png'}  
        )
        
        # ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì •í™•í•œ URL ìƒì„±
        file_url = f"https://{bucket_name}.s3.amazonaws.com/{s3_key}"
        
        return file_url

    except Exception as e:
        print(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

############################
######### api_rag ##########
############################


def get_embedding(text):
    """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (OpenAI ìµœì‹  API ì‚¬ìš©)"""
    try:
        client = openai.OpenAI(api_key=OPENAI_API_KEY)  # ìµœì‹  í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
        response = client.embeddings.create(
            input=text,
            model="text-embedding-ada-002"
        )
        return response.data[0].embedding  # ë³€ê²½ëœ ì¸í„°í˜ì´ìŠ¤
    except Exception as e:
        print(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def search_index(index, query, top_k=3, score_threshold=0.45):
    """ì£¼ì–´ì§„ Pinecone ì¸ë±ìŠ¤ì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (ìœ ì‚¬ë„ í•„í„°ë§ ì¶”ê°€)"""
    query_embedding = get_embedding(query)
    if not query_embedding:
        return []
    
    result = index.query(vector=query_embedding, top_k=top_k, include_metadata=True, include_values=False)
    matches = result.get("matches", []) if isinstance(result, dict) else result.matches

    # ìœ ì‚¬ë„ í•„í„°ë§ ì¶”ê°€
    filtered_chunks = [
        match["metadata"]["chunk_text"]
        for match in matches
        if "metadata" in match and "chunk_text" in match["metadata"]
        and match.get("score", 0) >= score_threshold
    ]

    return filtered_chunks


def generate_answer(query, relevant_texts, prompt_template):
    """LangChainì„ ì‚¬ìš©í•´ ë¬¸ë§¥ ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
    context = "\n\n".join(relevant_texts)
    
    prompt = PromptTemplate(
        input_variables=["context", "question"],
        template=prompt_template
    )
    
    try:
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            max_tokens=300,
            api_key=OPENAI_API_KEY
        )
        chain = LLMChain(llm=llm, prompt=prompt)
        return chain.run({"context": context, "question": query})
    except Exception as e:
        print(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
        return "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

@app.route('/rag_get_answer', methods=['POST'])
def get_answer():
    try:
        data = request.json
        if not data:
            return jsonify({"error": "Invalid JSON request"}), 400

        route_num = data.get("route_num")
        query = data.get("query")
        
        if route_num is None or query is None:
            return jsonify({"error": "route_numê³¼ queryê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        if route_num == 0:
            meritz_texts = search_index(index_meritz, query, top_k=3)
            samsung_texts = search_index(index_samsung, query, top_k=3)
            hanhwa_texts = search_index(index_hanhwa, query, top_k=3)
            
            if not any([meritz_texts, samsung_texts, hanhwa_texts]):
                return jsonify({"answer": "ì €ëŠ” ë³´í—˜ ê´€ë ¨ ë‚´ìš©ë§Œ ë‹µë³€í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."})
            
            relevant_texts = (
                ["[ë©”ë¦¬ì¸ ]\n" + "\n".join(meritz_texts)] +
                ["[ì‚¼ì„±í™”ì¬]\n" + "\n".join(samsung_texts)] +
                ["[í•œí™”]\n" + "\n".join(hanhwa_texts)]
            )

            prompt_template = (
                "ë‹¹ì‹ ì€ ë³´í—˜ ì¶”ì²œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ 3ê°œ ë³´í—˜ì‚¬ë¥¼ ë¹„êµí•˜ì—¬ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹µë³€ì„ 300ì ì´ë‚´ì˜ ì™„ê²°ëœ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n"
                "ë¬¸ë§¥: {context}\n\n"
                "ì§ˆë¬¸: {question}\n"
                "ë‹µë³€:"
            )
        
        elif route_num == 1:
            diagnostic_texts = search_index(index_diagnostic, query, top_k=7)
            
            if not diagnostic_texts:
                return jsonify({"answer": "ì €ëŠ” ë…¸ë ¹ê²¬ ê´€ë ¨ ì •ë³´ë§Œ ë‹µë³€í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."})
            
            relevant_texts = diagnostic_texts

            prompt_template = (
                "ë‹¹ì‹ ì€ ë…¸ë ¹ê²¬ ì „ë¬¸ ì •ë³´ ì œê³µ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹µë³€ì„ 300ì ì´ë‚´ì˜ ì™„ê²°ëœ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n"
                "ë¬¸ë§¥: {context}\n\n"
                "ì§ˆë¬¸: {question}\n"
                "ë‹µë³€:"
            )
        
        elif route_num == 2:
            relevant_texts = [str(funeral_data)]

            prompt_template = (
                "ë‹¹ì‹ ì€ ì¥ë¡€ì‹ì¥ ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                "ì•„ë˜ì˜ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ íŒŒì•…í•œ í›„ ê°€ì¥ ì í•©í•œ ì¥ë¡€ì‹ì¥ì„ ë¬¸ë§¥ì—ì„œ ì°¾ì•„ 300ì ì´ë‚´ì˜ ì™„ê²°ëœ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•´ ì•ˆë‚´í•´ì£¼ì„¸ìš”.\n"
                "ë¬¸ë§¥: {context}\n\n"
                "ì§ˆë¬¸: {question}\n"
                "ë‹µë³€:"
            )
        
        elif route_num == 3:
            answer = """ë‹¤ìŒì€ í«ë¡œìŠ¤ ì¦í›„êµ° ê·¹ë³µ í”„ë¡œê·¸ë¨ ë§í¬ ëª©ë¡ì…ë‹ˆë‹¤.\në§ˆì¸ë“œì¹´í˜ ì„¼í„°\n: https://center.mindcafe.co.kr/program_petloss\n\në§ˆìŒì¹˜ìœ ëª¨ì„ with í«ë¡œìŠ¤\n: https://www.gangnam.go.kr/contents/mind_healing/1/view.do?mid=ID04_04075401\n"""
            return jsonify({"answer": answer})
        
        else:
            return jsonify({"error": "route_num ê°’ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."}), 400
        
        try:
            answer = generate_answer(query, relevant_texts, prompt_template)
        except Exception as e:
            print(f"âŒ GPT ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return jsonify({"error": "Failed to generate answer"}), 500
        
        return jsonify({"answer": answer})
    
    except Exception as e:
        return jsonify({"error": f"Unexpected error: {e}"}), 500

############################
## api_letter_dreambooth ###
############################
           
def generate_letter_answer(memories, prompt, openai_api_key):
    if not memories or len(memories) < 2:  # ìµœì†Œí•œ ì„±ê²©(character)ê³¼ í’ˆì¢…(breed)ì´ ìˆì–´ì•¼ í•¨
        print("âŒ ì˜¤ë¥˜: memories ë¦¬ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ.")
        return "ê¸°ë³¸ì ì¸ ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    context = "\n\n".join(memories)
    
    full_prompt = PromptTemplate(
        input_variables=["context", "question"],
        template=(
            "ë¬¸ë§¥: {context}\n\n"
            "ì§ˆë¬¸: {question}\n"
            "ë‹µë³€:"
        )
    )
    
    try:
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.7,
            max_tokens=None,
            timeout=None,
            max_retries=2,
            api_key=openai_api_key
        )
        chain = LLMChain(llm=llm, prompt=full_prompt)
        answer = chain.run({"context": context, "question": prompt})
        return answer.strip()
    except Exception as e:
        print(f"âŒ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

def is_black_image(image, threshold=10):
    """ì´ë¯¸ì§€ê°€ ê±°ì˜ ê²€ì •ì¸ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
    grayscale = image.convert("L")  # í‘ë°±ìœ¼ë¡œ ë³€í™˜
    stat = ImageStat.Stat(grayscale)
    avg_brightness = stat.mean[0]
    return avg_brightness < threshold  # ë°ê¸° í‰ê· ì´ thresholdë³´ë‹¤ ì‘ìœ¼ë©´ ê²€ì •ìœ¼ë¡œ íŒë‹¨

def generate_dreambooth(dreambooth_prompt, pet_id):
    checkpoint_dir = "./dreambooth_output/checkpoint-450"
    
    unet = UNet2DConditionModel.from_pretrained(
        os.path.join(checkpoint_dir, "unet"),
        torch_dtype=torch.float16,
        local_files_only=True
    ).to(device)

    pipeline = DiffusionPipeline.from_pretrained(
        MODEL_NAME,
        unet=unet,
        torch_dtype=torch.float16
    ).to(device)
    
    lora_path = "./J_illustration.safetensors"
    pipeline.load_lora_weights(lora_path)

    max_guidance_scale = 13 # ê°€ì¥ í° ê°’ ì‚¬ìš©
    inference_steps = 100  # ê³ ì •ëœ ìŠ¤í… ìˆ˜
    generated_images = []

    for _ in range(6):
        result = pipeline(dreambooth_prompt, num_inference_steps=inference_steps, guidance_scale=max_guidance_scale)
        generated_images.append(result.images[0])

    # ìµœì¢… ì´ë¯¸ì§€ 6ì¥ ì„ íƒ
    encoded_images = []
    for idx, image in enumerate(generated_images[:6]):
        if is_black_image(image):
            print(f"âš ï¸ Skipped black image at index {idx}")
            continue

        local_path = f"generated_image_{idx}.png"

        # ì´ë¯¸ì§€ ì €ì¥
        image.save(local_path, format="PNG")
        print(f"âœ… Image saved locally: {local_path}")

        # S3 ì—…ë¡œë“œ
        file_url = upload_png_to_s3(BUCKET_NAME, local_path, pet_id)

        if file_url:
            encoded_images.append(file_url)
            print(f"âœ… Uploaded to S3: {file_url}")
        else:
            print(f"âŒ Failed to upload {local_path} to S3")

    # ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ
    shutil.rmtree("./dreambooth_output", ignore_errors=True)
    shutil.rmtree("./train_images", ignore_errors=True)

    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    del pipeline
    del unet
    pipeline = None
    unet = None

    torch.cuda.empty_cache()
    torch.cuda.synchronize()
    gc.collect()
    gc.collect()  # ì¶”ê°€ í˜¸ì¶œ
    torch.cuda.ipc_collect()
    
    return encoded_images

@app.route('/letter_train', methods=['POST'])
def train_dreambooth():
    try:
        data = request.json
        if not data:
            return jsonify({"error": "Invalid JSON request"}), 400

        image_urls = data.get("images", [])
        if not image_urls:
            return jsonify({"error": "No images provided"}), 400

        image_urls *= 2  # ë°ì´í„° ì¦ê°•
        
        download_s3_images(image_urls, "./train_images")

        command = [
            "accelerate", "launch", "--num_cpu_threads_per_process=4", TRAIN_SCRIPT,
            "--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5",
            "--instance_data_dir=./train_images",
            "--output_dir=./dreambooth_output",
            "--instance_prompt=a sks pet",
            "--resolution=256",
            "--train_batch_size=1",
            "--gradient_accumulation_steps=1",
            "--gradient_checkpointing",
            "--mixed_precision=fp16",
            "--learning_rate=5e-6",
            "--lr_scheduler=constant",
            "--lr_warmup_steps=0",
            "--max_train_steps=450",
            "--checkpointing_steps=450",
            "--enable_xformers_memory_efficient_attention",
            "--use_8bit_adam",
        ]

        def run_training():
            global training_status
            training_status["status"] = "running"
            try:
                print("ğŸš€ Training started in background...")
                subprocess.run(command, check=True)
                print("âœ… Training completed successfully!")
                training_status["status"] = "completed"
            except subprocess.CalledProcessError as e:
                print(f"âŒ Training failed: {e}")
                if "CUDA out of memory" in str(e) or "GPU" in str(e):
                    print("âš ï¸ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ ë°œìƒ. ëª¨ë¸ í›ˆë ¨ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.")
                    training_status["status"] = "failed - GPU memory issue"
                else:
                    training_status["status"] = "failed"
            except Exception as e:
                print(f"âš ï¸ Unexpected error during training: {e}")
                training_status["status"] = "failed"

        # ìƒˆë¡œìš´ ì“°ë ˆë“œì—ì„œ í›ˆë ¨ ì‹¤í–‰ (ë¹„ë™ê¸° ì²˜ë¦¬)
        training_thread = threading.Thread(target=run_training, daemon=True)
        training_thread.start()

        return jsonify({"message": "Training started"}), 202  # 202 Accepted: ë¹„ë™ê¸° ìš”ì²­
    
    except Exception as e:
        return jsonify({"error": f"Unexpected error: {e}"}), 500

@app.route('/training_status', methods=['GET'])
def get_training_status():
    return jsonify(training_status), 200

@app.route('/letter_generate', methods=['POST'])
def generate_images():
    
    # pipelineê³¼ unetì„ Noneìœ¼ë¡œ ì„¤ì •
    global pipeline, unet
    pipeline = None
    unet = None
    
    data = request.json
    if not data:
        return jsonify({"error": "Invalid JSON request"}), 400

    try:
        character = data.get("character", "")
        breed = data.get("breed", "")
        texts = data.get("texts", [])
        pet_id = int(data.get("pet_id", 0))
        pet_name = data.get("pet_name", "")
        member_name = data.get("member_name", "")
        nickname = data.get("nickname", "")
    except (ValueError, TypeError) as e:
        return jsonify({"error": f"Invalid data format: {e}"}), 400

    memories = [character, breed] + texts

    # GPTë¡œ í¸ì§€ ìƒì„±
    try:
        letter_prompt = f"ë°˜ë ¤ë™ë¬¼ì˜ ì„±ê²©ê³¼ ì¢…, ë°˜ë ¤ë™ë¬¼ê³¼ì˜ ì¶”ì–µì„ ê¸°ë¡í•œ ê²Œì‹œê¸€ì„ ë°”íƒ•ìœ¼ë¡œ ë°˜ë ¤ë™ë¬¼ì´ ì‚¬í›„ í•˜ëŠ˜ë‚˜ë¼ì—ì„œ ì£¼ì¸ì—ê²Œ ì“°ëŠ” í¸ì§€ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. ë”°ëœ»í•˜ê³  ê°ì„±ì ì¸ ëŠë‚Œìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë§íˆ¬ëŠ” ë°˜ë§ë¡œ í•´ì£¼ì„¸ìš”. ë°˜ë ¤ë™ë¬¼ì˜ ì´ë¦„ì€ {pet_name}ì…ë‹ˆë‹¤. ì£¼ì¸ì€ {nickname}ì˜ í˜¸ì¹­ìœ¼ë¡œ ë¶ˆëŸ¬ì£¼ì„¸ìš”."
        letter = generate_letter_answer(memories, letter_prompt, OPENAI_API_KEY)
    except Exception as e:
        return jsonify({"error": f"Letter generation failed: {e}"}), 500
    
    try:
        title_prompt = f"ì´ í¸ì§€ ë‚´ìš©ì˜ ì œëª©ì„ 10ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
        title = generate_letter_answer(letter, title_prompt, OPENAI_API_KEY)
    except Exception as e:
        return jsonify({"error": f"Letter generation failed: {e}"}), 500
    
    title = "ğŸ’Œ " + title
    
    print("â­ title: ", title)

    # GPTë¡œ DreamBooth í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ
    try:
        prompt_extraction = f"ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ DreamBooth ëª¨ë¸ì— ì í•©í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ì–´ë¡œ ì•„ì£¼ ì§§ê²Œ ìƒì„±í•˜ì„¸ìš”. ìƒì„± ëŒ€ìƒì¸ ë°˜ë ¤ë™ë¬¼ ì¢…ë¥˜ëŠ” {breed}ì´ê³  'a sks ...' í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤."
        dreambooth_prompt = generate_letter_answer(memories, prompt_extraction, OPENAI_API_KEY)
        dreambooth_prompt = "high quality, J_illustration, " + dreambooth_prompt
    except Exception as e:
        return jsonify({"error": f"Prompt extraction failed: {e}"}), 500
    
    print("ğŸˆ dreambooth_prompt :", dreambooth_prompt)

    try:
        encoded_images = generate_dreambooth(dreambooth_prompt, pet_id)
    except Exception as e:
        return jsonify({"error": f"Dreambooth generation failed: {e}"}), 500
    
    return jsonify({"images": encoded_images, "letter": letter, "title": title})

@app.route('/letter_generate_random', methods=['POST'])
def generate_images_random():
    
    data = request.json
    if not data:
        return jsonify({"error": "Invalid JSON request"}), 400

    try:
        character = data.get("character", "")
        breed = data.get("breed", "")
        pet_name = data.get("pet_name", "")
        member_name = data.get("member_name", "")
        nickname = data.get("nickname", "")
    except (ValueError, TypeError) as e:
        return jsonify({"error": f"Invalid data format: {e}"}), 400

    memories = [character, breed]

    # GPTë¡œ í¸ì§€ ìƒì„±
    try:
        letter_topics = [
            "ë¬´ì§€ê°œ ë‹¤ë¦¬ ê±´ë„ˆì—ì„œì˜ ë‚˜ë‚ ë“¤", "ë„ˆì™€ í•¨ê»˜í–ˆë˜ ê°€ì¥ í–‰ë³µí•œ ìˆœê°„", "ì²˜ìŒ ë„ˆë¥¼ ë§Œë‚¬ì„ ë•Œì˜ ê¸°ì–µ",
            "ë‚´ê°€ ê°€ì¥ ì¢‹ì•„í–ˆë˜ ìŒì‹ê³¼ ê°„ì‹", "ë‚´ê°€ ê°€ì¥ ì¢‹ì•„í–ˆë˜ ì¥ì†Œ", "ìš°ë¦¬ë§Œì˜ íŠ¹ë³„í•œ ì˜ì‹",
            "ë„¤ê°€ í•´ì¤€ ìµœê³ ì˜ ë³´ì‚´í•Œ", "ë‚´ê°€ ê°€ë” ì‚¬ê³ ë¥¼ ì³¤ì„ ë•Œì˜ ì´ì•¼ê¸°", "ë„ˆë¥¼ ë³´ë©° ëŠê¼ˆë˜ ë”°ëœ»í•œ ê°ì •",
            "ë‚˜ë¥¼ ì²˜ìŒ ë¶ˆë €ì„ ë•Œì˜ ê¸°ì–µ", "ë‚˜ë¥¼ ì²˜ìŒ ì“°ë‹¤ë“¬ì—ˆì„ ë•Œì˜ ê¸°ë¶„", "ë„¤ê°€ ë‚˜ë¥¼ ìœ„í•´ í•´ì¤€ ê°€ì¥ íŠ¹ë³„í•œ ì¼"
        ]
        letter_topic = random.choice(letter_topics)
        memories = [character, breed] + [letter_topic]

        letter_prompt = f"ë°˜ë ¤ë™ë¬¼ì˜ ì„±ê²©ê³¼ ì¢…, ë°˜ë ¤ë™ë¬¼ê³¼ì˜ ì¶”ì–µì„ ê¸°ë¡í•œ ê²Œì‹œê¸€ì„ ë°”íƒ•ìœ¼ë¡œ {letter_topic}ì„ ì£¼ì œë¡œ ë°˜ë ¤ë™ë¬¼ì´ ì‚¬í›„ í•˜ëŠ˜ë‚˜ë¼ì—ì„œ ì£¼ì¸ì—ê²Œ ì“°ëŠ” ì•ˆë¶€ ì¸ì‚¬ í¸ì§€ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. ë”°ëœ»í•˜ê³  ê°ì„±ì ì€ ë¬¸ì²´ë¡œ ì‘ì„±í•´ ì£¼ì£¼ì„¸ìš”. ë§íˆ¬ëŠ” ë°˜ë§ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. ë°˜ë ¤ë™ë¬¼ì˜ ì´ë¦„ì€ {pet_name}ì…ë‹ˆë‹¤. ì£¼ì¸ì€ {nickname}ì˜ í˜¸ì¹­ìœ¼ë¡œ ë¶ˆëŸ¬ì£¼ì„¸ìš”."
        letter = generate_letter_answer(memories, letter_prompt, OPENAI_API_KEY)
    except Exception as e:
        return jsonify({"error": f"Letter generation failed: {e}"}), 500
    
    try:
        title_prompt = f"ì´ í¸ì§€ ë‚´ìš©ì˜ ì œëª©ì„ 10ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
        title = generate_letter_answer(letter, title_prompt, OPENAI_API_KEY)
    except Exception as e:
        return jsonify({"error": f"Letter generation failed: {e}"}), 500
    
    title = "ğŸ’Œ " + title
    
    print("â­ title: ", title)
    
    return jsonify({"letter": letter, "title": title})

@app.route('/letter_generate_birth_death', methods=['POST'])
def generate_images_birth_death():
    # pipelineê³¼ unetì„ Noneìœ¼ë¡œ ì„¤ì •
    global pipeline, unet
    pipeline = None
    unet = None
    
    data = request.json
    if not data:
        return jsonify({"error": "Invalid JSON request"}), 400

    try:
        character = data.get("character", "")
        breed = data.get("breed", "")
        texts = data.get("texts", []) # ìƒì¼, ì‚¬ë§ì¼
        pet_id = int(data.get("pet_id", 0))
        pet_name = data.get("pet_name", "")
        member_name = data.get("member_name", "")
        nickname = data.get("nickname", "")
    except (ValueError, TypeError) as e:
        return jsonify({"error": f"Invalid data format: {e}"}), 400

    memories = [character, breed] + texts

    # GPTë¡œ í¸ì§€ ìƒì„±
    try:
        letter_prompt = f"ì˜¤ëŠ˜ì€ íŠ¹ë³„í•œ ë‚ ì…ë‹ˆë‹¤. ë°˜ë ¤ë™ë¬¼ì˜ ì„±ê²©ê³¼ ì¢…, ë°˜ë ¤ë™ë¬¼ê³¼ì˜ ì¶”ì–µì„ ê¸°ë¡í•œ ê²Œì‹œê¸€ì„ ë°”íƒ•ìœ¼ë¡œ ë°˜ë ¤ë™ë¬¼ì˜ {texts[0]}ì„ ì£¼ì œë¡œ ë°˜ë ¤ë™ë¬¼ì´ ì‚¬í›„ í•˜ëŠ˜ë‚˜ë¼ì—ì„œ ì£¼ì¸ì—ê²Œ ì“°ëŠ” ì•ˆë¶€ ì¸ì‚¬ í¸ì§€ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. ë¬¸ì²´ëŠ” ë”°ëœ»í•˜ê³  ê°ì„±ì ì¸ ëŠë‚Œìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. ë§íˆ¬ëŠ” ë°˜ë§ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. ë°˜ë ¤ë™ë¬¼ì˜ ì´ë¦„ì€ {pet_name}ì´ê³  ì£¼ì¸ì˜ ì´ë¦„ì€ {member_name}ì…ë‹ˆë‹¤. ì£¼ì¸ì€ {nickname}ì˜ í˜¸ì¹­ìœ¼ë¡œ ë¶ˆëŸ¬ì£¼ì„¸ìš”."
        letter = generate_letter_answer(memories, letter_prompt, OPENAI_API_KEY)
    except Exception as e:
        return jsonify({"error": f"Letter generation failed: {e}"}), 500
    
    try:
        title_prompt = f"ì´ í¸ì§€ ë‚´ìš©ì˜ ì œëª©ì„ 10ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
        title = generate_letter_answer(letter, title_prompt, OPENAI_API_KEY)
    except Exception as e:
        return jsonify({"error": f"Letter generation failed: {e}"}), 500
    
    if texts[0] == "ìƒì¼":
        title = "ğŸ‚" + title
    elif texts[0] == "ê¸°ì¼":    
        title = "ğŸª¦" + title

    # GPTë¡œ DreamBooth í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ
    try:
        if texts[0] == "ìƒì¼":
            prompt_extraction = f"ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ DreamBooth ëª¨ë¸ì— ì í•©í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ì–´ë¡œ ì•„ì£¼ ì§§ê²Œ ìƒì„±í•˜ì„¸ìš”. ìƒì„± ëŒ€ìƒì¸ ë°˜ë ¤ë™ë¬¼ ì¢…ë¥˜ëŠ” {breed}ì´ê³  ìƒì¼ì¼€ì´í¬ ì•ì—ì„œ í–‰ë³µí•´í•˜ëŠ” ë°˜ë ¤ë™ë¬¼ì˜ ëª¨ìŠµì„ ìƒì„±í•˜ë ¤ê³  í•©ë‹ˆë‹¤. 'a sks ...' í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤."
            dreambooth_prompt = generate_letter_answer(memories, prompt_extraction, OPENAI_API_KEY)
            dreambooth_prompt = "high quality, J_illustration, " + dreambooth_prompt
        elif texts[0]  == "ê¸°ì¼":
            prompt_extraction = f"ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ DreamBooth ëª¨ë¸ì— ì í•©í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ì–´ë¡œ ì•„ì£¼ ì§§ê²Œ ìƒì„±í•˜ì„¸ìš”. ìƒì„± ëŒ€ìƒì¸ ë°˜ë ¤ë™ë¬¼ ì¢…ë¥˜ëŠ” {breed}ì´ê³  ë¬´ì§€ê°œì™€ ë³„ë¹›ì„ ë°°ê²½ìœ¼ë¡œ ë°˜ë ¤ë™ë¬¼ì´ í–‰ë³µí•˜ê²Œ ì§€ë‚´ëŠ” ëª¨ìŠµì„ ìƒì„±í•˜ë ¤ê³  í•©ë‹ˆë‹¤. 'a sks ...' í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤."
            dreambooth_prompt = generate_letter_answer(memories, prompt_extraction, OPENAI_API_KEY)
            dreambooth_prompt = "high quality, J_illustration, " + dreambooth_prompt
    except Exception as e:
        return jsonify({"error": f"Prompt extraction failed: {e}"}), 500
    
    print("ğŸˆ dreambooth_prompt :", dreambooth_prompt)

    try:
        encoded_images = generate_dreambooth(dreambooth_prompt, pet_id)
    except Exception as e:
        return jsonify({"error": f"Dreambooth generation failed: {e}"}), 500
    
    return jsonify({"images": encoded_images, "letter": letter, "title": title})

############################
######### api_stars ########
############################

def process_segmentation(image, mask, edge_threshold1=50, edge_threshold2=150,
                         scale_factor=0.9, mask_threshold=30, max_internal_points=1000):
    """
    1) ë§ˆìŠ¤í¬ì—ì„œ ê°€ì¥ í° ìœ¤ê³½ì„ ì„ ì°¾ì•„ ì¼ì • ê°„ê²©ìœ¼ë¡œ ì ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    2) ë§ˆìŠ¤í¬ ë‚´ë¶€ ì˜ì—­ì— ëŒ€í•´ Canny ì—ì§€ ê²€ì¶œ í›„ ì—ì§€ ì ë“¤ì„ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.
    3) ë‘ ì¢…ë¥˜ì˜ ì (ìœ¤ê³½ì„ , ë‚´ë¶€ ì—ì§€)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if mask.sum() == 0:
        raise ValueError("The mask is empty. Check the input image or segmentation result.")

    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ (ì»¬ëŸ¬ ì´ë¯¸ì§€ì¸ ê²½ìš°)
    if len(image.shape) == 3:
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray_image = image

    # ë§ˆìŠ¤í¬ ì´ì§„í™”
    _, mask_uint8 = cv2.threshold((mask * 255).astype(np.uint8), mask_threshold, 255, cv2.THRESH_BINARY)
    
    # ìœ¤ê³½ì„  ì¶”ì¶œ
    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        raise ValueError("No contours found. Check the mask content.")

    # ê°€ì¥ í° ìœ¤ê³½ì„  ì„ íƒ
    largest_contour = max(contours, key=cv2.contourArea)

    # ìœ¤ê³½ì„  ê·¼ì‚¬
    epsilon = 0.01 * cv2.arcLength(largest_contour, True)
    approx_contour = cv2.approxPolyDP(largest_contour, epsilon, True)
    contour_points = approx_contour[:, 0, :]
    if len(contour_points) < 50:
        contour_points = largest_contour[:, 0, :]

    # ì  ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ì‹œê°í™” ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŒ)
    step = max(1, len(contour_points) // 60)
    contour_points = contour_points[::step]

    # ë‚´ë¶€ ì˜ì—­ ë§ˆìŠ¤í¬ (scale_factor ë§Œí¼ ì¤„ì¸ í›„ ì¤‘ì•™ ì •ë ¬)
    scaled_mask = cv2.resize(mask_uint8, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)
    dh = (mask.shape[0] - scaled_mask.shape[0]) // 2
    dw = (mask.shape[1] - scaled_mask.shape[1]) // 2
    scaled_mask_padded = cv2.copyMakeBorder(
        scaled_mask,
        top=dh,
        bottom=(mask.shape[0] - scaled_mask.shape[0] - dh),
        left=dw,
        right=(mask.shape[1] - scaled_mask.shape[1] - dw),
        borderType=cv2.BORDER_CONSTANT,
        value=0
    )

    # Canny ì—£ì§€ ê²€ì¶œ
    edges = cv2.Canny(gray_image, edge_threshold1, edge_threshold2)
    # ë‚´ë¶€ ì˜ì—­ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ì—ì§€ ì œê±°
    edges[scaled_mask_padded == 0] = 0

    # ì—ì§€ ì  ì¶”ì¶œ
    edge_y, edge_x = np.where(edges > 0)
    edge_points = np.stack((edge_x, edge_y), axis=-1)
    num_points = edge_points.shape[0]
    
    # ìµœëŒ€ max_internal_points ê°œë¡œ ìƒ˜í”Œë§ (ë” ë§ì´ ë½‘íˆë„ë¡ 500 -> max_internal_points)
    num_sample = min(num_points, max_internal_points)
    if num_points > 0:
        random_indices = np.random.choice(num_points, num_sample, replace=False)
        random_edge_points = edge_points[random_indices]
    else:
        random_edge_points = np.empty((0, 2), dtype=int)

    return contour_points, random_edge_points
    
def sample_pidinet_edges(pidinet_output, mask, scale_factor=0.9, sample_size=1000):
    """
    pidinet ê²°ê³¼ì—ì„œ í°ìƒ‰(ì „ê²½) ë¶€ë¶„ì„ ìƒ˜í”Œë§í•˜ëŠ” í•¨ìˆ˜
    1) ë§ˆìŠ¤í¬ì—ì„œ ê°€ì¥ í° ìœ¤ê³½ì„ ì„ ì°¾ì•„ ì¼ì • ê°„ê²©ìœ¼ë¡œ ì ë“¤ì„ ì¶”ì¶œ
    2) pidinet ì¶œë ¥ì—ì„œ ë§ˆìŠ¤í¬ ë‚´ë¶€ì˜ í°ìƒ‰(ì „ê²½) ì ë“¤ì„ ìƒ˜í”Œë§
    """
    if mask.sum() == 0:
        raise ValueError("The mask is empty. Check the input image or segmentation result.")
    
    # pidinet_outputì„ numpy ë°°ì—´ë¡œ ë³€í™˜
    if not isinstance(pidinet_output, np.ndarray):
        pidinet_output = np.array(pidinet_output.convert("L"))  # í‘ë°± ë³€í™˜
    
    # ë§ˆìŠ¤í¬ ì´ì§„í™”
    _, mask_uint8 = cv2.threshold((mask * 255).astype(np.uint8), 30, 255, cv2.THRESH_BINARY)
    
    # ìœ¤ê³½ì„  ì¶”ì¶œ
    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        raise ValueError("No contours found. Check the mask content.")
    
    # ê°€ì¥ í° ìœ¤ê³½ì„  ì„ íƒ
    largest_contour = max(contours, key=cv2.contourArea)
    
    # ìœ¤ê³½ì„  ê·¼ì‚¬í™” ë° ìƒ˜í”Œë§
    epsilon = 0.01 * cv2.arcLength(largest_contour, True)
    approx_contour = cv2.approxPolyDP(largest_contour, epsilon, True)
    contour_points = approx_contour[:, 0, :]
    
    if len(contour_points) < 50:
        contour_points = largest_contour[:, 0, :]
    
    step = max(1, len(contour_points) // 60)
    contour_points = contour_points[::step]
    
    # ë‚´ë¶€ ì˜ì—­ ë§ˆìŠ¤í¬(scale_factor ë§Œí¼ ì¶•ì†Œ)
    scaled_mask = cv2.resize(mask_uint8, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)
    dh = (mask.shape[0] - scaled_mask.shape[0]) // 2
    dw = (mask.shape[1] - scaled_mask.shape[1]) // 2
    scaled_mask_padded = cv2.copyMakeBorder(
        scaled_mask, dh, mask.shape[0] - scaled_mask.shape[0] - dh, 
        dw, mask.shape[1] - scaled_mask.shape[1] - dw, 
        borderType=cv2.BORDER_CONSTANT, value=0
    )

    # ê¸°ë³¸ threshold ê°’ ë° ì„¤ì •
    base_threshold = 0
    min_threshold = 5
    max_threshold = 40
    target_ratio = 0.05  # ëª©í‘œ í°ìƒ‰ ë¹„ìœ¨
    scaling_factor = 10  # ë³€í™”ëŸ‰ ì¡°ì ˆ

    # ì „ì²´ í”½ì…€ì—ì„œ í°ìƒ‰ ë¹„ìœ¨ ê³„ì‚°
    total_pixels = np.sum(scaled_mask_padded > 0)  # ë§ˆìŠ¤í¬ ë‚´ë¶€ì˜ ìœ íš¨ í”½ì…€ ê°œìˆ˜
    edge_pixels = np.sum(pidinet_output > base_threshold)  # ì´ˆê¸° thresholdì—ì„œ ê²€ì¶œëœ í”½ì…€ ê°œìˆ˜
    white_ratio = edge_pixels / total_pixels if total_pixels > 0 else 0  # í°ìƒ‰ ë¹„ìœ¨

    # ì„ í˜• ìŠ¤ì¼€ì¼ë§ì„ í™œìš©í•œ ë™ì  threshold ê³„ì‚°
    dynamic_threshold = base_threshold + scaling_factor * (white_ratio - target_ratio)
    # dynamic_threshold = np.clip(dynamic_threshold, min_threshold, max_threshold)  # min~max ì œí•œ/
    dynamic_threshold = 15

    # ìƒˆë¡œìš´ thresholdë¡œ í°ìƒ‰ í”½ì…€ ì°¾ê¸°
    edge_y, edge_x = np.where((pidinet_output > dynamic_threshold) & (scaled_mask_padded > 0))
    edge_points = np.stack((edge_x, edge_y), axis=-1)

    print(f"White Ratio: {white_ratio:.4f}, Adjusted Threshold: {dynamic_threshold:.2f}")
    
    # ìƒ˜í”Œë§ ìˆ˜í–‰ (ë§ˆìŠ¤í¬ ë‚´ë¶€ì—ì„œ ì„ íƒ)
    num_points = edge_points.shape[0]
    num_sample = min(num_points, sample_size)
    if num_points > 0:
        random_indices = np.random.choice(num_points, num_sample, replace=False)
        random_edge_points = edge_points[random_indices]
    else:
        random_edge_points = np.empty((0, 2), dtype=int)
    
    return contour_points, random_edge_points

def load_and_preprocess_image(image_path):
    """ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {image_path}")
    
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    return image, image_rgb

# def run_sam_segmentation(image_rgb, predictor, point):
#     """SAM ëª¨ë¸ì„ ì´ìš©í•´ ë§ˆìŠ¤í¬ ì˜ˆì¸¡ ìˆ˜í–‰"""
#     predictor.set_image(image_rgb)
    
#     h, w, _ = image_rgb.shape
#     point = np.array([point])
#     input_label = np.array([1])  # 1: object

#     masks, scores, _ = predictor.predict(
#         point_coords=point,
#         point_labels=input_label,
#         multimask_output=True,
#     )

#     best_mask_index = int(np.argmax(scores))
#     return masks[best_mask_index]

def extract_and_sort_centroids(contour_points, n_clusters, n_points):
    """
    ì£¼ì–´ì§„ ì»¨íˆ¬ì–´ í¬ì¸íŠ¸ì—ì„œ K-Means í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•˜ì—¬ 
    n_points ê°œì˜ ì¤‘ì‹¬ì ì„ ëœë¤í•˜ê²Œ ì„ íƒí•œ í›„, ê°€ì¥ ê°€ê¹Œìš´ ì ë“¤ë¡œ ì •ë ¬í•˜ëŠ” í•¨ìˆ˜.

    :param contour_points: (N, 2) í˜•íƒœì˜ numpy ë°°ì—´, ì»¨íˆ¬ì–´ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸
    :param n_clusters: í´ëŸ¬ìŠ¤í„° ê°œìˆ˜
    :param n_points: ì„ íƒí•  ì¤‘ì‹¬ì  ê°œìˆ˜
    :return: ìµœê·¼ì ‘ ìˆœì„œë¡œ ì •ë ¬ëœ ì¤‘ì‹¬ì  ë¦¬ìŠ¤íŠ¸
    """
    if len(contour_points) < n_clusters:
        raise ValueError("Contour points ê°œìˆ˜ê°€ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ë³´ë‹¤ ë§ì•„ì•¼ í•©ë‹ˆë‹¤.")

    # K-Means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    kmeans.fit(contour_points)

    # ì¤‘ì‹¬ì (centroids) ê°€ì ¸ì˜¤ê¸°
    centroids = kmeans.cluster_centers_

    # ì¤‘ì‹¬ì  ì¤‘ n_points ê°œ ëœë¤ ì„ íƒ
    num_selected = min(n_points, n_clusters)
    selected_centroids = np.array(random.sample(centroids.tolist(), num_selected))

    # ìµœê·¼ì ‘ ì´ì›ƒ ë°©ì‹ìœ¼ë¡œ ì •ë ¬
    sorted_centroids = nearest_neighbor_sort(selected_centroids)

    return sorted_centroids

def nearest_neighbor_sort(points):
    """
    ìµœê·¼ì ‘ ì´ì›ƒ(Nearest Neighbor) ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì ë“¤ì„ ì •ë ¬í•˜ëŠ” í•¨ìˆ˜.

    :param points: (N, 2) í˜•íƒœì˜ numpy ë°°ì—´, ëœë¤ ì„ íƒëœ ì¤‘ì‹¬ì  ë¦¬ìŠ¤íŠ¸
    :return: ìµœê·¼ì ‘ ìˆœì„œë¡œ ì •ë ¬ëœ numpy ë°°ì—´
    """
    points = points.tolist()
    sorted_points = [points.pop(0)]  # ì²« ë²ˆì§¸ ì ì„ ì‹œì‘ì ìœ¼ë¡œ ì„¤ì •

    while points:
        last_point = sorted_points[-1]
        nearest_point = min(points, key=lambda p: np.linalg.norm(np.array(p) - np.array(last_point)))
        sorted_points.append(nearest_point)
        points.remove(nearest_point)

    return np.array(sorted_points)

def generate_mst_graph(major_points):
    """MSTë¥¼ ìƒì„±í•˜ê³  ì—°ê²°ì„ ë³´ì¥í•˜ëŠ” í•¨ìˆ˜"""
    knn_graph = kneighbors_graph(major_points, n_neighbors=3, mode='distance')
    mst_matrix = minimum_spanning_tree(knn_graph)
    coo = mst_matrix.tocoo()
    edges = np.vstack((coo.row, coo.col)).T

    n_components, labels = connected_components(mst_matrix)
    if n_components > 1:
        distance_matrix = pairwise_distances(major_points)
        added_edges = []

        for i in range(n_components - 1):
            for j in range(i + 1, n_components):
                mask_i, mask_j = labels == i, labels == j
                min_dist, min_edge = np.inf, None

                for idx_i in np.where(mask_i)[0]:
                    for idx_j in np.where(mask_j)[0]:
                        if distance_matrix[idx_i, idx_j] < min_dist:
                            min_dist = distance_matrix[idx_i, idx_j]
                            min_edge = (idx_i, idx_j)

                if min_edge:
                    added_edges.append(min_edge)

        edges = np.vstack((edges, added_edges))
    
    return edges

def image_to_svg(image, svg_path, threshold=128):
    """Convert a processed grayscale image to SVG"""
    height, width = image.shape  # Ensure it's 2D
    dwg = svgwrite.Drawing(svg_path, size=(width, height))
    dwg.attribs['opacity'] = '0.245' 

    for y in range(height):
        for x in range(width):
            if image[y, x] >= threshold:  # Keep high-contrast areas
                dwg.add(dwg.circle(center=(x, y), r=1, fill='#A8C4F7', stroke='none'))
    
    dwg.save()

def enhance_contrast(image):
    """Convert image to grayscale and enhance contrast using CLAHE"""
    if len(image.shape) == 3:  # Convert to grayscale if the image has multiple channels
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()

    # Ensure the image is 8-bit (uint8)
    gray = np.clip(gray, 0, 255).astype(np.uint8)

    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    return enhanced

def enhance_contrast_rgb(image):
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)

    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)

    enhanced_lab = cv2.merge((cl, a, b))
    enhanced_img = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)
    return enhanced_img

@app.route("/stars_run_pidinet", methods=["POST"])
def run_pidinet():
    try:
        data = request.json
        print(f"ğŸ“¥ Received Data: {data}")

        image_url = data.get("image_url")
        if not image_url:
            return jsonify({"error": "No images provided"}), 400

        if isinstance(image_url, str):
            image_url = [image_url]

        stars_download_s3_images(image_urls=image_url, save_folder="./img")

        command = [
            "python", "pidinet-master/main.py",
            "--model", "pidinet_converted",
            "--config", "carv4",
            "--sa", "--dil",
            "-j", "4",
            "--gpu", "0",
            "--resume",
            "--savedir", "./img_edges",
            "--datadir", "./img",
            "--dataset", "Custom",
            "--evaluate", "./table5_pidinet.pth",
            "--evaluate-converted"
        ]

        try:
            print("ğŸš€ PiDiNet ì‹¤í–‰ ì¤‘...")
            subprocess.run(command, check=True)
            print("âœ… PiDiNet ì‹¤í–‰ ì™„ë£Œ!")
            return jsonify({"message": "PiDiNet execution completed"}), 200
        except subprocess.CalledProcessError as e:
            print(f"âŒ PiDiNet ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return jsonify({"error": "PiDiNet execution failed"}), 500
    
    except Exception as e:
        return jsonify({"error": f"Unexpected error: {e}"}), 500

@app.route("/stars_process_image", methods=["POST"])
def process_image():
    try:
        data = request.json
        image_url = data.get("image_url")
        point = data.get("point")

        if not image_url:
            return jsonify({"error": "No image URL provided"}), 400
        
        image_name = os.path.basename(image_url)
        image_path = "./img/" + image_name
        
        # # /////////////////////////////////////////////
        
        img = cv2.imread(image_path)
        
        response = requests.get(image_url)
        img_array = np.asarray(bytearray(response.content), dtype=np.uint8)
        img_yolo = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        enhanced_img = enhance_contrast_rgb(img_yolo)
        
        results = yolo_model(enhanced_img, imgsz=512)
        boxes = results[0].boxes.xyxy.cpu().numpy()

        x = point[0]
        y = point[1]

        selected_box = None
        min_area = float("inf")

        for box in boxes:
            x1, y1, x2, y2 = box
            if x1 <= x <= x2 and y1 <= y <= y2:
                area = (x2 - x1) * (y2 - y1)
                if area < min_area:
                    min_area = area
                    selected_box = box
     
        if selected_box is not None:
            sam_results = sam_model(image_path, bboxes=[selected_box])
            mask = sam_results[0].masks.data[0].cpu().numpy()
        else:
            print("ì ì— í•´ë‹¹í•˜ëŠ” ê°ì²´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        
        # /////////////////////////////////////////////
        
        image, image_rgb = load_and_preprocess_image(image_path)
        # mask = run_sam_segmentation(image_rgb, predictor, point)

        mask_ratio = np.count_nonzero(mask) / mask.size
        max_internal_points = int(mask_ratio * 3000)
        
        contour_points2, internal_points2 = process_segmentation(image, mask, max_internal_points=max_internal_points)
        
        image_path = f"./img_edges/eval_results/imgs_epoch_019/{os.path.splitext(image_name)[0]}.png"
        try:
            image = Image.open(image_path)
            image = np.array(image.convert("L"))
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return jsonify({"error": "Failed to load edge image"}), 500
        
        masked_image = np.zeros_like(image, dtype=np.float32)
        masked_image[mask > 0] = image[mask > 0]
        processed_image = enhance_contrast(masked_image)

        svg_path = f"{os.path.splitext(image_name)[0]}.svg"
        png_path = f"{os.path.splitext(image_name)[0]}_masked.png"
        
        try:
            image_to_svg(processed_image, svg_path)
            cairosvg.svg2png(url=svg_path, write_to=png_path)
            svg_url = upload_svg_to_s3(BUCKET_NAME, svg_path)
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return jsonify({"error": "Failed to upload SVG file"}), 500

        contour_points1, internal_points1 = sample_pidinet_edges(image, mask, sample_size=max_internal_points)
        internal_points = np.vstack((internal_points1, internal_points2))
        contour_points = np.vstack((contour_points2))

        major_contour = extract_and_sort_centroids(contour_points, n_clusters=20, n_points=5)
        major_internal = extract_and_sort_centroids(internal_points, n_clusters=20, n_points=10)
        major_points = np.vstack((major_contour, major_internal))
        edges = generate_mst_graph(major_points)

        return jsonify({
            "svg_path": svg_url,
            "edges": edges.tolist(),
            "major_points": major_points.astype(int).tolist()
        })
    
    except Exception as e:
        return jsonify({"error": f"Unexpected error: {e}"}), 500


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)